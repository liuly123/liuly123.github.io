<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>Tensorflow笔记 | Liuly的笔记本</title>
  <meta name="keywords" content="">
  <meta name="description" content="Tensorflow笔记 | Liuly的笔记本">
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
<meta name="description" content="安装https:&#x2F;&#x2F;mirrors.tuna.tsinghua.edu.cn&#x2F;help&#x2F;tensorflow&#x2F; 需要先安装pip： sudo apt install python-pip 选择Linux，cp27，1.3.0，复制代码安装 123pip install \  -i https:&#x2F;&#x2F;pypi.tuna.tsinghua.edu.cn&#x2F;simple&#x2F; \  https:&#x2F;&#x2F;mirror">
<meta property="og:type" content="article">
<meta property="og:title" content="Tensorflow笔记">
<meta property="og:url" content="https://liuly123.github.io/2020/03/06/Tensorflow%E7%AC%94%E8%AE%B0/index.html">
<meta property="og:site_name" content="Liuly的笔记本">
<meta property="og:description" content="安装https:&#x2F;&#x2F;mirrors.tuna.tsinghua.edu.cn&#x2F;help&#x2F;tensorflow&#x2F; 需要先安装pip： sudo apt install python-pip 选择Linux，cp27，1.3.0，复制代码安装 123pip install \  -i https:&#x2F;&#x2F;pypi.tuna.tsinghua.edu.cn&#x2F;simple&#x2F; \  https:&#x2F;&#x2F;mirror">
<meta property="article:published_time" content="2020-03-06T09:11:02.000Z">
<meta property="article:modified_time" content="2020-03-06T09:11:04.126Z">
<meta property="article:author" content="liuly">
<meta name="twitter:card" content="summary">


<link rel="icon" href="/img/avatar.jpg">

<link href="/css/style.css?v=1.0.1" rel="stylesheet">

<link href="/css/hl_theme/sublime.css?v=1.0.1" rel="stylesheet">

<link href="//cdn.bootcss.com/animate.css/3.5.2/animate.min.css" rel="stylesheet">
<link href="//cdn.bootcss.com/font-awesome/4.7.0/css/font-awesome.min.css" rel="stylesheet">

<script src="//cdn.bootcss.com/jquery/2.2.4/jquery.min.js"></script>
<script src="/js/jquery.autocomplete.min.js?v=1.0.1" ></script>

<script src="//cdn.bootcss.com/highlight.js/9.12.0/highlight.min.js"></script>
<script>
    hljs.initHighlightingOnLoad();
</script>

<script src="//cdn.bootcss.com/nprogress/0.2.0/nprogress.min.js"></script>



<script src="//cdn.bootcss.com/jquery-cookie/1.4.1/jquery.cookie.min.js" ></script>

<script src="/js/iconfont.js?v=1.0.1" ></script>

<meta name="generator" content="Hexo 4.2.0"></head>
<div style="display: none">
  <input class="theme_disqus_on" value="false">
  <input class="theme_preload_comment" value="false">
  <input class="theme_blog_path" value="">
</div>

<body>
<aside class="nav">
    <div class="nav-left">
        <a href="/" class="avatar_target">
    <img class="avatar" src="/img/avatar.jpg" />
</a>
<div class="author">
    <span>liuly</span>
</div>

<div class="icon">
    
        
        <a title="rss" href="/atom.xml" target="_blank">
            
                <svg class="iconfont-svg" aria-hidden="true">
                    <use xlink:href="#icon-rss"></use>
                </svg>
            
        </a>
        
    
        
        <a title="github" href="https://github.com/liuly123" target="_blank">
            
                <svg class="iconfont-svg" aria-hidden="true">
                    <use xlink:href="#icon-github"></use>
                </svg>
            
        </a>
        
    
        
        <a title="email" href="mailto:liulyabc@gmail.com" target="_blank">
            
                <svg class="iconfont-svg" aria-hidden="true">
                    <use xlink:href="#icon-email"></use>
                </svg>
            
        </a>
        
    
        
        <a title="qq" href="http://wpa.qq.com/msgrd?v=3&uin=2240057686&site=qq&menu=yes" target="_blank">
            
                <svg class="iconfont-svg" aria-hidden="true">
                    <use xlink:href="#icon-qq"></use>
                </svg>
            
        </a>
        
    
        
        <a title="neteasemusic" href="https://music.163.com/#/user/home?id=314223832" target="_blank">
            
                <svg class="iconfont-svg" aria-hidden="true">
                    <use xlink:href="#icon-neteasemusic"></use>
                </svg>
            
        </a>
        
    
</div>




<ul>
    <li><div class="all active">全部文章<small>(3)</small></div></li>
    
</ul>
<div class="left-bottom">
    <div class="menus">
    
    
    
    
    </div>
    <div><a class="about  site_url"  href="/about">关于</a></div>
</div>
<input type="hidden" id="yelog_site_posts_number" value="3">
<input type="hidden" id="yelog_site_word_count" value="2.8k">
<div style="display: none">
    <span id="busuanzi_value_site_uv"></span>
    <span id="busuanzi_value_site_pv"></span>
</div>

    </div>
    <div class="nav-right">
        <div class="friends-area">
    <div class="friends-title">
        友情链接
        <i class="back-title-list"></i>
    </div>
    <div class="friends-content">
        <ul>
            
        </ul>
    </div>
</div>
        <div class="title-list">
    <form onkeydown="if(event.keyCode === 13){return false;}">
        <input id="local-search-input" class="search" type="text" placeholder="以 in: 开头进行全文搜索" />
        <i class="cross"></i>
        <span>
            <label for="tagswitch">Tags:</label>
            <input id="tagswitch" type="checkbox" style="display: none" />
            <i id="tagsWitchIcon"></i>
        </span>
    </form>
    <div class="tags-list">
    
    <div class="clearfix"></div>
</div>

    
    <div id="local-search-result">

    </div>
    
    <nav id="title-list-nav">
        
        <a  class=""
           href="/2020/03/06/Ubuntu%E9%85%8D%E7%BD%AE/"
           data-tag=""
           data-author="" >
            <span class="post-title" title="Ubuntu常用命令">Ubuntu常用命令</span>
            <span class="post-date" title="2020-03-06 16:48:14">2020/03/06</span>
        </a>
        
        <a  class=""
           href="/2020/03/06/GitHub/"
           data-tag=""
           data-author="" >
            <span class="post-title" title="GitHub常用命令">GitHub常用命令</span>
            <span class="post-date" title="2020-03-06 16:48:14">2020/03/06</span>
        </a>
        
        <a  class=""
           href="/2020/03/06/Tensorflow%E7%AC%94%E8%AE%B0/"
           data-tag=""
           data-author="" >
            <span class="post-title" title="Tensorflow笔记">Tensorflow笔记</span>
            <span class="post-date" title="2020-03-06 17:11:02">2020/03/06</span>
        </a>
        
    </nav>
</div>
    </div>
    <div class="hide-list">
        <div class="semicircle">
            <div class="brackets first"><</div>
            <div class="brackets">&gt;</div>
        </div>
    </div>
</aside>
<div class="post">
    <div class="pjax">
        <article id="post-Tensorflow笔记" class="article article-type-post" itemscope itemprop="blogPost">
    
        <h1 class="article-title">Tensorflow笔记</h1>
    
    <div class="article-meta">
        
        
        
        
    </div>
    <div class="article-meta">
        
        创建时间:<time class="date" title='更新时间: 2020-03-06 17:11:04'>2020-03-06 17:11</time>
        
    </div>
    <div class="article-meta">
        
        <span>字数:1.5k</span>
        
        
        
    </div>
    
    <div class="toc-ref">
    
        <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#安装"><span class="toc-text">安装</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Tensorflow框架"><span class="toc-text">Tensorflow框架</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#计算图和会话"><span class="toc-text">计算图和会话</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#前向传播"><span class="toc-text">前向传播</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#反向传播（训练）"><span class="toc-text">反向传播（训练）</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#神经网络优化"><span class="toc-text">神经网络优化</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#损失函数-loss-：预测值-y-与已知答案-y-的差距"><span class="toc-text">损失函数(loss)：预测值(y)与已知答案(y_)的差距</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#学习率-learning-rate-：每次参数更新的幅度"><span class="toc-text">学习率(learning_rate)：每次参数更新的幅度</span></a></li></ol></li></ol></li></ol></li></ol>
    
<style>
    .left-col .switch-btn,
    .left-col .switch-area {
        display: none;
    }
    .toc-level-3 i,
    .toc-level-3 ol {
        display: none !important;
    }
</style>
</div>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h1><p><a href="https://mirrors.tuna.tsinghua.edu.cn/help/tensorflow/" target="_blank" rel="noopener">https://mirrors.tuna.tsinghua.edu.cn/help/tensorflow/</a></p>
<p>需要先安装pip： <code>sudo apt install python-pip</code></p>
<p>选择<code>Linux</code>，<code>cp27</code>，<code>1.3.0</code>，复制代码安装</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">pip install \</span><br><span class="line">  -i https://pypi.tuna.tsinghua.edu.cn/simple/ \</span><br><span class="line">  https://mirrors.tuna.tsinghua.edu.cn/tensorflow/linux/cpu/tensorflow-1.3.0-cp27-none-linux_x86_64.whl</span><br></pre></td></tr></table></figure>

<p>测试</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">python</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line">tf.__version__</span><br></pre></td></tr></table></figure>

<p>设置vim</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">vim ~/.vimrc</span><br><span class="line"><span class="built_in">set</span> ts=4</span><br><span class="line"><span class="built_in">set</span> nu</span><br></pre></td></tr></table></figure>

<h1 id="Tensorflow框架"><a href="#Tensorflow框架" class="headerlink" title="Tensorflow框架"></a>Tensorflow框架</h1><h4 id="计算图和会话"><a href="#计算图和会话" class="headerlink" title="计算图和会话"></a>计算图和会话</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#coding:utf-8</span></span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line">x = tf.constant([[<span class="number">1.0</span>,<span class="number">2.0</span>]])</span><br><span class="line">w = tf.constant([[<span class="number">3.0</span>],[<span class="number">4.0</span>]])</span><br><span class="line">y = tf.matmul(x,w)<span class="comment">#x与w相乘</span></span><br><span class="line"><span class="keyword">print</span> y</span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:<span class="comment">#（这是一个用来计算的会话）不带with后面的，就不计算结果，就只是网络框架</span></span><br><span class="line">	<span class="keyword">print</span> sess.run(y)</span><br></pre></td></tr></table></figure>

<h4 id="前向传播"><a href="#前向传播" class="headerlink" title="前向传播"></a>前向传播</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#coding:utf-8</span></span><br><span class="line"><span class="comment">#两层简单神经网络（全连接），两输入，一输出，隐含层三个神经元</span></span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="comment">#输入层，一行两列</span></span><br><span class="line">x = tf.constant([[<span class="number">0.7</span>,<span class="number">0.5</span>]])</span><br><span class="line"><span class="comment">#网络层的权值，一层神经元有两组连接，权值用随机数生成</span></span><br><span class="line">w1 = tf.Variable(tf.random_normal([<span class="number">2</span>,<span class="number">3</span>],stddev=<span class="number">1</span>,seed=<span class="number">1</span>))</span><br><span class="line">w2 = tf.Variable(tf.random_normal([<span class="number">3</span>,<span class="number">1</span>],stddev=<span class="number">1</span>,seed=<span class="number">1</span>))</span><br><span class="line"><span class="comment">#前向传播过程</span></span><br><span class="line">a = tf.matmul(x,w1)<span class="comment">#x与w1矩阵乘</span></span><br><span class="line">y = tf.matmul(a,w2)<span class="comment">#a与w2乘</span></span><br><span class="line"><span class="comment">#用会话计算结果</span></span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">	init_op = tf.global_variables_initializer()</span><br><span class="line">	sess.run(init_op)</span><br><span class="line">	<span class="keyword">print</span> sess.run(y)</span><br></pre></td></tr></table></figure>

<h4 id="反向传播（训练）"><a href="#反向传播（训练）" class="headerlink" title="反向传播（训练）"></a>反向传播（训练）</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#!/usr/bin/python2.7</span></span><br><span class="line"><span class="comment"># coding:utf-8</span></span><br><span class="line"><span class="comment"># 喂数据，并训练，共有32组样本</span></span><br><span class="line"><span class="comment"># 学习目标：输入为两个随机数，两数和&lt;1时，输出1，否则输出0</span></span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> numpy</span><br><span class="line">BATCH_SIZE = <span class="number">8</span></span><br><span class="line">seed = <span class="number">23455</span></span><br><span class="line"><span class="comment"># 基于seed产生随机数：实例化一个随机数生成器</span></span><br><span class="line">rdm = numpy.random.RandomState(seed)</span><br><span class="line"><span class="comment"># 生成32行2列的随机数作为输入</span></span><br><span class="line">X = rdm.rand(<span class="number">32</span>, <span class="number">2</span>)</span><br><span class="line"><span class="comment"># 从X输入的两个数小于1时，Y输出1</span></span><br><span class="line">Y = [[int(x0 + x1 &lt; <span class="number">1</span>)] <span class="keyword">for</span> (x0, x1) <span class="keyword">in</span> X]</span><br><span class="line"><span class="comment"># 打印样本</span></span><br><span class="line"><span class="keyword">print</span> <span class="string">"X:\n"</span>, X</span><br><span class="line"><span class="keyword">print</span> <span class="string">"Y:\n"</span>, Y</span><br><span class="line"><span class="comment"># 神经网络的输入输出占位</span></span><br><span class="line">x = tf.placeholder(tf.float32, shape=(<span class="literal">None</span>, <span class="number">2</span>))</span><br><span class="line">y_ = tf.placeholder(tf.float32, shape=(<span class="literal">None</span>, <span class="number">1</span>))</span><br><span class="line"><span class="comment"># 随机生成网络权值</span></span><br><span class="line">w1 = tf.Variable(tf.random_normal([<span class="number">2</span>, <span class="number">3</span>], stddev=<span class="number">1</span>, seed=<span class="number">1</span>))</span><br><span class="line">w2 = tf.Variable(tf.random_normal([<span class="number">3</span>, <span class="number">1</span>], stddev=<span class="number">1</span>, seed=<span class="number">1</span>))</span><br><span class="line"><span class="comment"># 相乘</span></span><br><span class="line">a = tf.matmul(x, w1)</span><br><span class="line">y = tf.matmul(a, w2)</span><br><span class="line"><span class="comment"># 损失函数</span></span><br><span class="line">loss = tf.reduce_mean(tf.square(y-y_))</span><br><span class="line"><span class="comment"># 反向传播（训练）方法，步长=0.001，损失函数值=loss</span></span><br><span class="line">train_step = tf.train.GradientDescentOptimizer(<span class="number">0.001</span>).minimize(loss)</span><br><span class="line"><span class="comment">#train_step = tf.train.MomentumOptimizer(0.001, 0.9).minimize(loss)</span></span><br><span class="line"><span class="comment">#train_step = tf.train.AdamOptimizer(0.001).minimize(loss)</span></span><br><span class="line"><span class="comment"># 生成会话来用样本训练模型</span></span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    init_op = tf.global_variables_initializer()  <span class="comment"># 初始化参数</span></span><br><span class="line">    sess.run(init_op)</span><br><span class="line">    <span class="comment"># 打印出未经训练的模型</span></span><br><span class="line">    <span class="keyword">print</span><span class="string">"w1:\n"</span>, sess.run(w1)</span><br><span class="line">    <span class="keyword">print</span><span class="string">"w2:\n"</span>, sess.run(w2)</span><br><span class="line">    <span class="comment"># 训练模型</span></span><br><span class="line">    STEPS = <span class="number">3000</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(STEPS):</span><br><span class="line">        start = (i*BATCH_SIZE) % <span class="number">32</span>  <span class="comment"># 每次喂8组数据:0～8,8~16,16~24,24~32</span></span><br><span class="line">        end = start + BATCH_SIZE</span><br><span class="line">        <span class="comment"># 喂数据训练，使用X[start,end]方式可以超出列表范围，使用X[place]不能超出索引</span></span><br><span class="line">        sess.run(train_step, feed_dict=&#123;x: X[start:end], y_: Y[start:end]&#125;)</span><br><span class="line">        <span class="keyword">if</span> i % <span class="number">500</span> == <span class="number">0</span>:</span><br><span class="line">            total_loss = sess.run(loss, feed_dict=&#123;x: X, y_: Y&#125;)</span><br><span class="line">            print(<span class="string">"训练%d轮后，损失函数值为%g"</span> % (i, total_loss))</span><br><span class="line">    <span class="comment"># 打印训练后的参数</span></span><br><span class="line">    <span class="keyword">print</span><span class="string">"\n"</span></span><br><span class="line">    <span class="keyword">print</span><span class="string">"w1:\n"</span>, sess.run(w1)</span><br><span class="line">    <span class="keyword">print</span><span class="string">"w2:\n"</span>, sess.run(w2)</span><br></pre></td></tr></table></figure>

<h2 id="神经网络优化"><a href="#神经网络优化" class="headerlink" title="神经网络优化"></a>神经网络优化</h2><h4 id="损失函数-loss-：预测值-y-与已知答案-y-的差距"><a href="#损失函数-loss-：预测值-y-与已知答案-y-的差距" class="headerlink" title="损失函数(loss)：预测值(y)与已知答案(y_)的差距"></a>损失函数(loss)：预测值(y)与已知答案(y_)的差距</h4><p>主流的有三种：</p>
<ul>
<li><strong>均方误差mes(Mean Squared Error)</strong><br>$$<br>MSE(y_,y)=\frac{\sum_{i=1}^n(y-y_)^2}{n}<br>$$</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">loss_mse = tf.reduce_mean(tf.square(y-y_))</span><br></pre></td></tr></table></figure>

<ul>
<li><p><strong>交叉熵ce(Cross Entropy)</strong></p>
<p>表征两个概率分布之间的距离<br>$$<br>H(y_,y)=-\sum_{i=1}^n(y_*logy)<br>$$</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">loss_ce = -tf.reduce_mean(y_*tf.log(tf.clip_by_value(y, <span class="number">1e-12</span>, <span class="number">1.0</span>)))<span class="comment">#1e-12防止值为0</span></span><br></pre></td></tr></table></figure>

<p>当y有n个可能的输出值（即n分类）时，y_与每个y的ce符合概率分布（概率的和为1），使用softmax()函数<br>$$<br>softmax(y_{i})=\frac{e^{y_{i}}}{\sum_{j=1}^{n}e^{y_{i}}}<br>$$</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">ce = tf.nn.sparse_softmax_cross_entropy_with_logits(</span><br><span class="line">    logits=y, labels=tf.argmax(y_, <span class="number">1</span>))</span><br><span class="line">lose_ce = tf.reduce_mean(ce)</span><br></pre></td></tr></table></figure>
</li>
<li><p><strong>自定义损失函数</strong></p>
<p>例如<br>$$<br>loss(y_,y)=\sum_{i=1}^{n}f(y_,y)\<br>f(y_,y)=\left{<br>\begin{aligned}<br>PROFIT<em>(y_-y) \quad y&lt;y_ \quad 预测值小于实际值时，误差乘上PROFIT \<br>COST</em>(y-y_) \quad y&gt;=y_ \quad 预测值大于误差值时，误差乘以COST<br>\end{aligned}<br>\right.<br>$$</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">loss = tf.reduce_mean(tf.where(tf.grater(y, y_), COST*(y-y_), PROFIT*(y_-y)))</span><br></pre></td></tr></table></figure>

</li>
</ul>
<p><strong>一个训练的示例，损失函数采用均方误差</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#!/usr/bin/python2.7</span></span><br><span class="line"><span class="comment"># coding:utf-8</span></span><br><span class="line"><span class="comment"># 喂数据，并训练，共有32组样本</span></span><br><span class="line"><span class="comment"># 学习目标：Y=x1+x2，并加入随机噪声-0.05~0.05</span></span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> numpy</span><br><span class="line">BATCH_SIZE = <span class="number">8</span></span><br><span class="line">seed = <span class="number">23455</span></span><br><span class="line">rdm = numpy.random.RandomState(seed)</span><br><span class="line"><span class="comment"># 目标模型</span></span><br><span class="line">X = rdm.rand(<span class="number">32</span>, <span class="number">2</span>)</span><br><span class="line">Y_ = [[x1+x2+(rdm.rand()/<span class="number">10.0</span><span class="number">-0.05</span>)] <span class="keyword">for</span> (x1, x2) <span class="keyword">in</span> X]</span><br><span class="line"><span class="comment"># 神经网络模型，单层，没有隐含层</span></span><br><span class="line">x = tf.placeholder(tf.float32, shape=(<span class="literal">None</span>, <span class="number">2</span>))</span><br><span class="line">y_ = tf.placeholder(tf.float32, shape=(<span class="literal">None</span>, <span class="number">1</span>))</span><br><span class="line">w1 = tf.Variable(tf.random_normal([<span class="number">2</span>, <span class="number">1</span>], stddev=<span class="number">1</span>, seed=<span class="number">1</span>))</span><br><span class="line">y = tf.matmul(x, w1)</span><br><span class="line"><span class="comment"># 损失函数为MSE（均方误差）</span></span><br><span class="line">loss_mse = tf.reduce_mean(tf.square(y-y_))</span><br><span class="line"><span class="comment"># 训练过程为梯度下降法</span></span><br><span class="line">train_step = tf.train.GradientDescentOptimizer(<span class="number">0.001</span>).minimize(loss_mse)</span><br><span class="line"><span class="comment"># 生成会话，训练STEP轮</span></span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    init_op = tf.global_variables_initializer()</span><br><span class="line">    sess.run(init_op)</span><br><span class="line">    STEPS = <span class="number">20000</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(STEPS):</span><br><span class="line">        start = (i*BATCH_SIZE) % <span class="number">32</span></span><br><span class="line">        end = start + BATCH_SIZE</span><br><span class="line">        sess.run(train_step, feed_dict=&#123;x: X[start:end], y_: Y_[start:end]&#125;)</span><br><span class="line">        <span class="keyword">if</span> i % <span class="number">500</span> == <span class="number">0</span>:</span><br><span class="line">            total_loss = sess.run(loss_mse, feed_dict=&#123;x: X, y_: Y_&#125;)</span><br><span class="line">            print(<span class="string">"训练%d轮后，损失函数值为%g"</span> % (i, total_loss))</span><br><span class="line">            <span class="keyword">print</span> <span class="string">"w1为：\n"</span>, sess.run(w1)</span><br><span class="line">    <span class="comment"># 打印训练后的参数</span></span><br><span class="line">    <span class="keyword">print</span> (<span class="string">"\n"</span>)</span><br><span class="line">    <span class="keyword">print</span> <span class="string">"w1:\n"</span>, sess.run(w1)</span><br></pre></td></tr></table></figure>

<h4 id="学习率-learning-rate-：每次参数更新的幅度"><a href="#学习率-learning-rate-：每次参数更新的幅度" class="headerlink" title="学习率(learning_rate)：每次参数更新的幅度"></a>学习率(learning_rate)：每次参数更新的幅度</h4><p>$$<br>W_{n_1}=W_{n}-learning_rate*\nabla<br>$$</p>
<p>​            ▽为损失函数的梯度(倒数)，learning_rate为常数(用户自定义的学习率)</p>
<p><strong>指数衰减学习率</strong><br>$$<br>learning_rate=LEARNING_RATE_BASE*{LEARNING_RATE_DECAY}^{\frac{global_step}{LEARNING_RATE_STEP}}<br>$$</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#!/usr/bin/python2.7</span></span><br><span class="line"><span class="comment"># coding:utf-8</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 单神经元，自定义损失函数loss=(w+1)^2，学习率为0.2，w初值为5；为了使loss最小时，w的最终结果应为-1</span></span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line">w = tf.Variable(tf.constant(<span class="number">5</span>, dtype=tf.float32))  <span class="comment"># 神经网络</span></span><br><span class="line">loss = tf.square(w+<span class="number">1</span>)  <span class="comment"># 损失函数</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 指数衰减学习率参数</span></span><br><span class="line">LEARNING_RATE_BASE = <span class="number">0.1</span>  <span class="comment"># 最初学习率</span></span><br><span class="line">LEARNING_RATE_DECAY = <span class="number">0.99</span>  <span class="comment"># 学习率的衰减率</span></span><br><span class="line">LEARNING_RATE_STEP = <span class="number">2</span>  <span class="comment"># 每多少轮更新一次学习率，一般为:样本总数/BATCH_SIZE</span></span><br><span class="line">global_step = tf.Variable(<span class="number">0</span>, trainable=<span class="literal">False</span>)  <span class="comment"># 当前是第几轮</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义学习率</span></span><br><span class="line">learning_rate = tf.train.exponential_decay(</span><br><span class="line">    LEARNING_RATE_BASE, global_step, LEARNING_RATE_STEP,</span><br><span class="line">    LEARNING_RATE_DECAY, staircase=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 反向传播方法</span></span><br><span class="line">train_step = tf.train.GradientDescentOptimizer(</span><br><span class="line">    learning_rate).minimize(loss, global_step=global_step)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义会话，训练40轮</span></span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    init_op = tf.global_variables_initializer()</span><br><span class="line">    sess.run(init_op)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">40</span>):</span><br><span class="line">        sess.run(train_step)</span><br><span class="line">        <span class="comment"># 数据打印</span></span><br><span class="line">        learning_rate_val = sess.run(learning_rate)</span><br><span class="line">        w_val = sess.run(w)</span><br><span class="line">        loss_val = sess.run(loss)</span><br><span class="line">        learning_rate_val = sess.run(learning_rate)</span><br><span class="line">        global_step_val = sess.run(global_step)</span><br><span class="line">        <span class="keyword">print</span> <span class="string">"训练%s轮后，w值为%f，loss值为%f，学习率为%s，step为%s"</span> % (</span><br><span class="line">            i, w_val, loss_val, learning_rate_val, global_step_val)</span><br></pre></td></tr></table></figure>




      
       <hr><span style="font-style: italic;color: gray;"> 转载请注明来源，欢迎对文章中的引用来源进行考证，欢迎指出任何有错误或不够清晰的表达。可以邮件至liulyabc@gmail.com </span>
    </div>
</article>



<div class="article_copyright">
    <p><span class="copy-title">文章标题:</span>Tensorflow笔记</p>
    <p><span class="copy-title">文章字数:</span><span class="post-count">1.5k</span></p>
    <p><span class="copy-title">本文作者:</span><a  title="liuly">liuly</a></p>
    <p><span class="copy-title">发布时间:</span>2020-03-06, 17:11:02</p>
    <p><span class="copy-title">最后更新:</span>2020-03-06, 17:11:04</p>
    <span class="copy-title">原始链接:</span><a class="post-url" href="/2020/03/06/Tensorflow%E7%AC%94%E8%AE%B0/" title="Tensorflow笔记">https://liuly123.github.io/2020/03/06/Tensorflow%E7%AC%94%E8%AE%B0/</a>
    <p>
        <span class="copy-title">版权声明:</span><i class="fa fa-creative-commons"></i> <a rel="license noopener" href="http://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank" title="CC BY-NC-SA 4.0 International" target = "_blank">"署名-非商用-相同方式共享 4.0"</a> 转载请保留原文链接及作者。
    </p>
</div>





    
        <!-- MathJax配置，可通过单美元符号书写行内公式等 -->
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
    "HTML-CSS": {
        preferredFont: "TeX",
        availableFonts: ["STIX","TeX"],
        linebreaks: { automatic:true },
        EqnChunk: (MathJax.Hub.Browser.isMobile ? 10 : 50)
    },
    tex2jax: {
        inlineMath: [ ["$", "$"], ["\\(","\\)"] ],
        processEscapes: true,
        ignoreClass: "tex2jax_ignore|dno",
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    },
    TeX: {
        equationNumbers: { autoNumber: "AMS" },
        noUndefined: { attributes: { mathcolor: "red", mathbackground: "#FFEEEE", mathsize: "90%" } },
        Macros: { href: "{}" }
    },
    messageStyle: "none"
    });
</script>
<!-- 给MathJax元素添加has-jax class -->
<script type="text/x-mathjax-config">
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for(i=0; i < all.length; i += 1) {
            all[i].SourceElement().parentNode.className += ' has-jax';
        }
    });
</script>
<!-- 通过连接CDN加载MathJax的js代码 -->
<script type="text/javascript" async
        src="//cdn.bootcss.com/mathjax/2.7.2/MathJax.js?config=TeX-MML-AM_CHTML">
</script>
<input type="hidden" id="MathJax-js"
        value="//cdn.bootcss.com/mathjax/2.7.2/MathJax.js?config=TeX-MML-AM_CHTML">
</input>
    




    </div>
    <div class="copyright">
        <p class="footer-entry">©2016-2020 Hexo</p>
<p class="footer-entry">Built with <a href="https://hexo.io/" target="_blank">Hexo</a> and <a href="https://github.com/yelog/hexo-theme-3-hexo" target="_blank">3-hexo</a> theme</p>

    </div>
    <div class="full-toc">
        <button class="full"><span class="min "></span></button>
<button class="post-toc-menu"><span class="post-toc-menu-icons"></span></button>
<div class="post-toc"><span class="post-toc-title">目录</span>
    <div class="post-toc-content">

    </div>
</div>
<a class="" id="rocket" ></a>

    </div>
</div>
<div class="acParent"></div>

</body>
<script src="/js/jquery.pjax.js?v=1.0.1" ></script>

<script src="/js/script.js?v=1.0.1" ></script>
<script>
    var img_resize = 'default';
    /*作者、标签的自动补全*/
    $(function () {
        $('.search').AutoComplete({
            'data': [],
            'itemHeight': 20,
            'width': 418
        }).AutoComplete('show');
    })
    function initArticle() {
        /*渲染对应的表格样式*/
        
            $(".post .pjax table").addClass("green_title");
        

        /*渲染打赏样式*/
        

        /*高亮代码块行号*/
        

        /*访问数量*/
        

        /*代码高亮，行号对齐*/
        $('.pre-numbering').css('line-height',$('.has-numbering').css('line-height'));

        
        
    }

    /*打赏页面隐藏与展示*/
    

</script>

<!--加入行号的高亮代码块样式-->

<!--自定义样式设置-->
<style>
    
    
    .nav {
        width: 542px;
    }
    .nav.fullscreen {
        margin-left: -542px;
    }
    .nav-left {
        width: 120px;
    }
    
    
    @media screen and (max-width: 1468px) {
        .nav {
            width: 492px;
        }
        .nav.fullscreen {
            margin-left: -492px;
        }
        .nav-left {
            width: 100px;
        }
    }
    
    
    @media screen and (max-width: 1024px) {
        .nav {
            width: 492px;
            margin-left: -492px
        }
        .nav.fullscreen {
            margin-left: 0;
        }
        .nav .hide-list.fullscreen {
            left: 492px
        }
    }
    
    @media screen and (max-width: 426px) {
        .nav {
            width: 100%;
        }
        .nav-left {
            width: 100%;
        }
    }
    
    
    .nav-right .title-list nav a .post-title, .nav-right .title-list #local-search-result a .post-title {
        color: #383636;
    }
    
    
    .nav-right .title-list nav a .post-date, .nav-right .title-list #local-search-result a .post-date {
        color: #5e5e5f;
    }
    
    
    .nav-right nav a.hover, #local-search-result a.hover{
        background-color: #e2e0e0;
    }
    
    

    /*列表样式*/
    
    .post .pjax article .article-entry>ol, .post .pjax article .article-entry>ul, .post .pjax article>ol, .post .pjax article>ul{
        border: #e2dede solid 1px;
        border-radius: 10px;
        padding: 10px 32px 10px 56px;
    }
    .post .pjax article .article-entry li>ol, .post .pjax article .article-entry li>ul,.post .pjax article li>ol, .post .pjax article li>ul{
        padding-top: 5px;
        padding-bottom: 5px;
    }
    .post .pjax article .article-entry>ol>li, .post .pjax article .article-entry>ul>li,.post .pjax article>ol>li, .post .pjax article>ul>li{
        margin-bottom: auto;
        margin-left: auto;
    }
    .post .pjax article .article-entry li>ol>li, .post .pjax article .article-entry li>ul>li,.post .pjax article li>ol>li, .post .pjax article li>ul>li{
        margin-bottom: auto;
        margin-left: auto;
    }
    

    /* 背景图样式 */
    
    


    /*引用块样式*/
    

    /*文章列表背景图*/
    
    .nav-right:before {
        content: ' ';
        display: block;
        position: absolute;
        left: 0;
        top: 0;
        width: 100%;
        height: 100%;
        opacity: 0.3;
        background: url("https://i.loli.net/2019/07/22/5d3521411f3f169375.png");
        background-repeat: no-repeat;
        background-position: 50% 0;
        -ms-background-size: cover;
        -o-background-size: cover;
        -moz-background-size: cover;
        -webkit-background-size: cover;
        background-size: cover;
    }
    

    
</style>







</html>
